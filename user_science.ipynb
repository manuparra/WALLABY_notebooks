{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25bb2fab-51dd-45a7-9c21-d3d611333a3d",
   "metadata": {},
   "source": [
    "# WALLABY Database Access Notebook\n",
    "\n",
    "<span style=\"font-weight: bold; color: #FF0000;\">⚠ Make sure the Jupyter Notebook server is loaded with the wallaby/python-3.9.1 module!</span>\n",
    "\n",
    "<span style=\"font-weight: bold; color: #FF0000;\">⚠ If the Jupyter Notebook server is not loaded with the wallaby/python-3.9.1 delete the interactive session and start a new one with the correct module.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd8a55e-8853-451c-9777-6b2992061fdf",
   "metadata": {},
   "source": [
    "## Connect to Database\n",
    "\n",
    "The first step will be to connect to the WALLAYBY database by importing the `wallaby` module and calling the `wallaby.connect()` function. This will connect you to the database using a generic WALLABY user account and provide read access to all data tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f7b92b9-8813-40dd-9990-78cab257af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import django\n",
    "from django.db import models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization import PercentileInterval\n",
    "from astroquery.skyview import SkyView\n",
    "from astropy.utils.data import clear_download_cache\n",
    "\n",
    "Run, Instance, Detection, Product, Source  = None, None, None, None, None\n",
    "SourceDetection, Comment, Tag, TagDetection, TagSourceDetection = None, None, None, None, None\n",
    "\n",
    "\n",
    "\n",
    "# utils\n",
    "def _write_bytesio_to_file(filename, bytesio):\n",
    "    \"\"\"Write the contents of the given BytesIO to a file.\n",
    "    Creates the file or overwrites the file if it does\n",
    "    not exist yet. \n",
    "    \n",
    "    \"\"\"\n",
    "    with open(filename, \"wb\") as outfile:\n",
    "        # Copy the BytesIO stream to the output file\n",
    "        outfile.write(bytesio.getbuffer())\n",
    "            \n",
    "\n",
    "def _write_zipped_fits_file(filename, product, compress=True):\n",
    "    \"\"\"Compress a .fits file as .fits.gz for a data product.\n",
    "   \n",
    "    \"\"\"\n",
    "    with io.BytesIO() as buf:\n",
    "        buf.write(product)\n",
    "        buf.seek(0)\n",
    "        if not os.path.isfile(filename):\n",
    "            _write_bytesio_to_file(filename, buf)\n",
    "            if compress:\n",
    "                os.system(f'gzip {filename}')\n",
    "\n",
    "\n",
    "def _write_products(products, prefix):\n",
    "    _write_zipped_fits_file('%s_cube.fits' % (prefix), products.cube)\n",
    "    _write_zipped_fits_file('%s_chan.fits' % (prefix), products.chan)\n",
    "    _write_zipped_fits_file('%s_mask.fits' % (prefix), products.mask)\n",
    "    _write_zipped_fits_file('%s_mom0.fits' % (prefix), products.mom0)\n",
    "    _write_zipped_fits_file('%s_mom1.fits' % (prefix), products.mom1)\n",
    "    _write_zipped_fits_file('%s_mom2.fits' % (prefix), products.mom2)\n",
    "\n",
    "    # Open spectrum\n",
    "    with io.BytesIO() as buf:\n",
    "        buf.write(b''.join(products.spec))\n",
    "        buf.seek(0)\n",
    "        spec_file  = '%s_spec.txt' % (prefix)\n",
    "        if not os.path.isfile(spec_file):\n",
    "            _write_bytesio_to_file(spec_file, buf)\n",
    "\n",
    "\n",
    "# Retrieve catalogue by tag\n",
    "def get_catalog(tag):\n",
    "    tag = str(tag)\n",
    "    if tag == \"\":\n",
    "        sys.stderr.write(\"Please specify a tag to extract a source catalogue, e.g.:\\ntable = get_catalog(tag=\\\"NGC 5044 DR1\\\")\\n\")\n",
    "        return None\n",
    "    \n",
    "    table = Table()\n",
    "    \n",
    "    # Get field names\n",
    "    detection_field_names = [field.name for field in Detection._meta.fields if not isinstance(field, models.ForeignKey)]\n",
    "    detection_field_names.remove(\"name\")\n",
    "    detection_field_names.remove(\"unresolved\")\n",
    "    detection_field_names.remove(\"v_opt\")\n",
    "    detection_field_names.remove(\"v_app\")\n",
    "    detection_field_names.remove(\"v_rad\")\n",
    "    detection_field_names.remove(\"l\")\n",
    "    detection_field_names.remove(\"b\")\n",
    "    detection_field_names.remove(\"v_opt_peak\")\n",
    "    detection_field_names.remove(\"v_app_peak\")\n",
    "    detection_field_names.remove(\"v_rad_peak\")\n",
    "    detection_field_names.remove(\"l_peak\")\n",
    "    detection_field_names.remove(\"b_peak\")\n",
    "    source_field_names = [field.name for field in Source._meta.fields if not isinstance(field, models.ForeignKey)]\n",
    "    source_field_names.remove(\"id\")\n",
    "    \n",
    "    # Get sources and detections\n",
    "    sources = [\n",
    "        Source.objects.get(id=sd.source_id) for sd in [\n",
    "            SourceDetection.objects.get(id=tsd.source_detection_id) for tsd in \n",
    "                TagSourceDetection.objects.filter(tag_id=Tag.objects.get(name=tag).id)\n",
    "        ]\n",
    "    ]\n",
    "    detections = [\n",
    "        Detection.objects.get(id=sd.detection_id) for sd in [\n",
    "            SourceDetection.objects.get(id=tsd.source_detection_id) for tsd in \n",
    "                TagSourceDetection.objects.filter(tag_id=Tag.objects.get(name=tag).id)\n",
    "        ]\n",
    "    ]\n",
    "    \n",
    "    # Add columns to the table\n",
    "    for field in source_field_names:\n",
    "        if field == 'name':\n",
    "            table[field] = [getattr(s, field) for s in sources]\n",
    "        else:\n",
    "            table[field] = np.array([getattr(s, field) for s in sources], dtype=float)\n",
    "    for field in detection_field_names:\n",
    "        table[field] = np.array([getattr(d, field) for d in detections], dtype=float)\n",
    "    \n",
    "    # Extract and add comments, if any\n",
    "    column_comments = []\n",
    "    for i in range(len(table)):\n",
    "        column_comments.append([])\n",
    "        comments = Comment.objects.filter(detection=table[\"id\"][i])\n",
    "        for comment in comments:\n",
    "            column_comments[i].append(comment.comment + \" (\" + comment.author + \")\")\n",
    "    table.add_column(col=column_comments, name=\"comments\")\n",
    "    \n",
    "    # Extract and add tags, if any\n",
    "    column_tags = []\n",
    "    for i in range(len(table)):\n",
    "        column_tags.append([])\n",
    "        tags = TagSourceDetection.objects.filter(source_detection_id=SourceDetection.objects.get(detection_id=table[\"id\"][i]))\n",
    "        for tag in tags:\n",
    "            column_tags[i].append(Tag.objects.get(id=tag.tag_id).name)\n",
    "    table.add_column(col=column_tags, name=\"tags\")\n",
    "    \n",
    "    return table\n",
    "\n",
    "\n",
    "def save_catalog(tag, *args, **kwargs):\n",
    "    \"\"\"Write catalog of tagged sources. Remove object columns for write to file.\n",
    "\n",
    "    \"\"\"\n",
    "    table = get_catalog(tag)\n",
    "    table.remove_columns(['comments', 'tags'])\n",
    "    table.write(*args, **kwargs)\n",
    "\n",
    "\n",
    "def save_products_for_source(tag, source_name, *args, **kwargs):\n",
    "    \"\"\"Save source finding output products for a given source name.\n",
    "\n",
    "    \"\"\"\n",
    "    table = get_catalog(tag)\n",
    "    try:\n",
    "        idx = list(table['name']).index(source_name)\n",
    "        row = table[idx]\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(\"Could not find source with provided name in tagged data.\")\n",
    "        return None\n",
    "    detection = Detection.objects.get(id=row['id'])\n",
    "    products = Product.objects.get(detection=detection)\n",
    "\n",
    "    name = source_name.replace(' ', '_')\n",
    "    parent = f'{name}_products'\n",
    "    if not os.path.isdir(parent):\n",
    "        os.mkdir(parent)\n",
    "    \n",
    "    # Write fits files\n",
    "    _write_products(products, f'{parent}/{name}')\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def save_products(tag, *args, **kwargs):\n",
    "    \"\"\"Save source finding output products for a given tag\n",
    "\n",
    "    \"\"\"\n",
    "    table = get_catalog(tag)\n",
    "    parent = '%s_products' % tag.replace(' ', '_')\n",
    "    if not os.path.isdir(parent):\n",
    "        os.mkdir(parent)\n",
    "\n",
    "    for row in table:\n",
    "        name = row['name'].replace(' ', '_')\n",
    "        if not os.path.isdir(f'{parent}/{name}'):\n",
    "            os.mkdir(f'{parent}/{name}')\n",
    "        detection = Detection.objects.get(id=row['id'])\n",
    "        products = Product.objects.get(detection=detection)\n",
    "        _write_products(products, f'{parent}/{name}/{name}')\n",
    "\n",
    "    os.system(f'tar -czf {parent}.tar.gz {parent}')\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# Print list of supported tags\n",
    "def print_tags():\n",
    "    tags = Tag.objects.all()\n",
    "    for tag in tags:\n",
    "        print(\"{:20s}\\t{:s}\".format(\"\\\"\" + tag.name + \"\\\"\", tag.description))\n",
    "    return\n",
    "\n",
    "\n",
    "# Retrieve FITS image from database\n",
    "def get_image(product):\n",
    "    with io.BytesIO() as buf:\n",
    "        buf.write(product)\n",
    "        buf.seek(0)\n",
    "        hdu = fits.open(buf)[0]\n",
    "        return hdu.data, hdu.header\n",
    "\n",
    "\n",
    "# Retrieve spectrum from database\n",
    "def get_spectrum(product):\n",
    "    with io.BytesIO() as buf:\n",
    "        buf.write(b\"\".join(product))\n",
    "        buf.seek(0)\n",
    "        return np.loadtxt(buf, dtype=\"float\", comments=\"#\", unpack=True)\n",
    "\n",
    "\n",
    "# Retrieve DSS image from Skyview\n",
    "def retrieve_dss_image(longitude, latitude, width, height):\n",
    "    hdulist = SkyView.get_images(\n",
    "        position=\"{}, {}\".format(longitude, latitude),\n",
    "        survey=[\"DSS\"],\n",
    "        coordinates=\"J2000\",\n",
    "        projection=\"Tan\",\n",
    "        width=width*u.deg,\n",
    "        height=height*u.deg,\n",
    "        cache=None\n",
    "    )\n",
    "    return hdulist[0][0]\n",
    "\n",
    "\n",
    "# Create overview plot\n",
    "def overview_plot(id):\n",
    "    interval = PercentileInterval(95.0)\n",
    "    plt.rcParams[\"figure.figsize\"] = (16, 12)\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    # Retrieve products from database\n",
    "    products = Product.objects.get(detection=id)\n",
    "    \n",
    "    # Open moment 0 image\n",
    "    mom0, header = get_image(products.mom0)\n",
    "    mom1, header = get_image(products.mom1)\n",
    "    spectrum = get_spectrum(products.spec)\n",
    "    wcs = WCS(header)\n",
    "    \n",
    "    # Extract coordinate information\n",
    "    nx = header[\"NAXIS1\"]\n",
    "    ny = header[\"NAXIS2\"]\n",
    "    lon, lat = wcs.all_pix2world(nx/2, ny/2, 0)\n",
    "    tmp1, tmp3 = wcs.all_pix2world(0, ny/2, 0)\n",
    "    tmp2, tmp4 = wcs.all_pix2world(nx, ny/2, 0)\n",
    "    width = np.rad2deg(math.acos(math.sin(np.deg2rad(tmp3)) * math.sin(np.deg2rad(tmp4)) + math.cos(np.deg2rad(tmp3)) * math.cos(np.deg2rad(tmp4)) * math.cos(np.deg2rad(tmp1 - tmp2))))\n",
    "    tmp1, tmp3 = wcs.all_pix2world(nx/2, 0, 0)\n",
    "    tmp2, tmp4 = wcs.all_pix2world(nx/2, ny, 0)\n",
    "    height = np.rad2deg(math.acos(math.sin(np.deg2rad(tmp3)) * math.sin(np.deg2rad(tmp4)) + math.cos(np.deg2rad(tmp3)) * math.cos(np.deg2rad(tmp4)) * math.cos(np.deg2rad(tmp1 - tmp2))))\n",
    "    \n",
    "    # Plot DSS image with HI contours\n",
    "    try:\n",
    "        hdu_opt = retrieve_dss_image(lon, lat, width, height)\n",
    "        wcs_opt = WCS(hdu_opt.header)\n",
    "        \n",
    "        bmin, bmax = interval.get_limits(hdu_opt.data)\n",
    "        ax = plt.subplot(2, 2, 2, projection=wcs_opt)\n",
    "        ax.imshow(hdu_opt.data, origin=\"lower\")\n",
    "        ax.contour(mom0, transform=ax.get_transform(wcs), levels=np.logspace(2.0, 5.0, 10), colors=\"lightgrey\", alpha=1.0)\n",
    "        ax.grid(color=\"grey\", ls=\"solid\")\n",
    "        ax.set_xlabel(\"Right ascension (J2000)\")\n",
    "        ax.set_ylabel(\"Declination (J2000)\")\n",
    "        ax.tick_params(axis=\"x\", which=\"both\", left=False, right=False)\n",
    "        ax.tick_params(axis=\"y\", which=\"both\", top=False, bottom=False)\n",
    "        ax.set_title(\"DSS + Moment 0\")\n",
    "        ax.set_aspect(np.abs(wcs_opt.wcs.cdelt[1] / wcs_opt.wcs.cdelt[0]))\n",
    "    except:\n",
    "        sys.stderr.write(\"Failed to retrieve DSS image.\\n\")\n",
    "        pass\n",
    "    \n",
    "    # Plot moment 0\n",
    "    ax2 = plt.subplot(2, 2, 1, projection=wcs)\n",
    "    ax2.imshow(mom0, origin=\"lower\")\n",
    "    ax2.grid(color=\"grey\", ls=\"solid\")\n",
    "    ax2.set_xlabel(\"Right ascension (J2000)\")\n",
    "    ax2.set_ylabel(\"Declination (J2000)\")\n",
    "    ax2.tick_params(axis=\"x\", which=\"both\", left=False, right=False)\n",
    "    ax2.tick_params(axis=\"y\", which=\"both\", top=False, bottom=False)\n",
    "    ax2.set_title(\"Moment 0\")\n",
    "    \n",
    "    # Add beam size\n",
    "    ax2.add_patch(Ellipse((5, 5), 5, 5, 0, edgecolor=\"grey\", facecolor=\"grey\"))\n",
    "\n",
    "    # Plot moment 1\n",
    "    bmin, bmax = interval.get_limits(mom1)\n",
    "    ax3 = plt.subplot(2, 2, 3, projection=wcs)\n",
    "    ax3.imshow(mom1, origin=\"lower\", vmin=bmin, vmax=bmax, cmap=plt.get_cmap(\"gist_rainbow\"))\n",
    "    ax3.grid(color=\"grey\", ls=\"solid\")\n",
    "    ax3.set_xlabel(\"Right ascension (J2000)\")\n",
    "    ax3.set_ylabel(\"Declination (J2000)\")\n",
    "    ax3.tick_params(axis=\"x\", which=\"both\", left=False, right=False)\n",
    "    ax3.tick_params(axis=\"y\", which=\"both\", top=False, bottom=False)\n",
    "    ax3.set_title(\"Moment 1\")\n",
    "    \n",
    "    # Plot spectrum\n",
    "    xaxis = spectrum[1] / 1e+6\n",
    "    data  = 1000.0 * np.nan_to_num(spectrum[2])\n",
    "    xmin = np.nanmin(xaxis)\n",
    "    xmax = np.nanmax(xaxis)\n",
    "    ymin = np.nanmin(data)\n",
    "    ymax = np.nanmax(data)\n",
    "    ymin -= 0.1 * (ymax - ymin)\n",
    "    ymax += 0.1 * (ymax - ymin)\n",
    "    ax4 = plt.subplot(2, 2, 4)\n",
    "    ax4.step(xaxis, data, where=\"mid\", color=\"royalblue\")\n",
    "    ax4.set_xlabel(\"Frequency (MHz)\")\n",
    "    ax4.set_ylabel(\"Flux density (mJy)\")\n",
    "    ax4.set_title(\"Spectrum\")\n",
    "    ax4.grid(True)\n",
    "    ax4.set_xlim([xmin, xmax])\n",
    "    ax4.set_ylim([ymin, ymax])\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt\n",
    "\n",
    "\n",
    "def save_overview(tag, *args, **kwargs):\n",
    "    \"\"\"Save overview plots for tagged sources\n",
    "\n",
    "    \"\"\"\n",
    "    table = get_catalog(tag)\n",
    "    parent = '%s_overview' % tag.replace(' ', '_')\n",
    "    if not os.path.isdir(parent):\n",
    "        os.mkdir(parent)    \n",
    "\n",
    "    for row in table:\n",
    "        name = row['name'].replace(' ', '_')\n",
    "        p = overview_plot(row['id'])\n",
    "        p.savefig(f\"{parent}/{name}_overview.png\")\n",
    "        p.close()\n",
    "\n",
    "    os.system(f'tar -czf {parent}.tar.gz {parent}')\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def parse_spectrum_to_table(spectrum):\n",
    "    \"\"\"Takes the spectrum stored in the database and parses the object to an Astropy.table\n",
    "    Columns: Channel, Frequency, Flux density, Pixels\n",
    "    \n",
    "    \"\"\"\n",
    "    array = []\n",
    "    with io.BytesIO() as buf:\n",
    "        buf.write(b''.join(spectrum))\n",
    "        buf.seek(0)\n",
    "        text = buf.getbuffer().tobytes().decode('utf-8')\n",
    "        lines = text.strip().split('\\n')\n",
    "        for line in lines:\n",
    "            if not line.startswith('#'):\n",
    "                chan, freq, flux, pix = line.strip().split()\n",
    "                array.append(np.array([int(chan), float(freq), float(flux), int(pix)]))\n",
    "\n",
    "    t = Table(\n",
    "        np.array(array),\n",
    "        names=('Channel', 'Frequency', 'Flux Density', 'Pixels'),\n",
    "        dtype=(int, np.float32, np.float32, int)\n",
    "    )\n",
    "    return t\n",
    "\n",
    "\n",
    "def casda_export_products(table, directory):\n",
    "    \"\"\"Export data products for sources in an astropy.Table object\n",
    "    to an output directory in a format compatible for CASDA ingest.\n",
    "\n",
    "    \"\"\"\n",
    "    for row in table:\n",
    "        name = row['name'].replace(' ', '_')\n",
    "        detection = Detection.objects.get(id=row['id'])\n",
    "        products = Product.objects.get(detection=detection)\n",
    "        filename_prefix = f'{directory}/{name}'\n",
    "        \n",
    "        # write .fits files\n",
    "        _write_zipped_fits_file('%s_cube.fits' % (filename_prefix), products.cube, compress=False)\n",
    "        _write_zipped_fits_file('%s_chan.fits' % (filename_prefix), products.chan, compress=False)\n",
    "        _write_zipped_fits_file('%s_mask.fits' % (filename_prefix), products.mask, compress=False)\n",
    "        _write_zipped_fits_file('%s_mom0.fits' % (filename_prefix), products.mom0, compress=False)\n",
    "        _write_zipped_fits_file('%s_mom1.fits' % (filename_prefix), products.mom1, compress=False)\n",
    "        _write_zipped_fits_file('%s_mom2.fits' % (filename_prefix), products.mom2, compress=False)\n",
    "\n",
    "        # write spectrum as fits file\n",
    "        spectrum_table = parse_spectrum_to_table(products.spec)\n",
    "        spectrum_table.write('%s_spec.fits' % (filename_prefix), format='fits')\n",
    "\n",
    "    return\n",
    "\n",
    "# Connect to WALLABY database\n",
    "def connect():\n",
    "    from django.conf import settings\n",
    "    global Run, Instance, Detection, Product, Source\n",
    "    global SourceDetection, Comment, Tag, TagDetection, TagSourceDetection\n",
    "  \n",
    "\n",
    "    settings.configure(\n",
    "        DATABASE_ENGINE = 'postgresql_psycopg2',\n",
    "        DATABASE_NAME = 'wallabydb',\n",
    "        DATABASE_USER = 'wallaby_user',\n",
    "        DATABASE_PASSWORD = 'wallaby_user',\n",
    "        DATABASE_HOST = '161.111.167.192',\n",
    "        DATABASE_PORT = '18020',\n",
    "        TIME_ZONE = 'Europe/Madrid',\n",
    "        DJANGO_SETTINGS_MODULE = \"api.settings\",\n",
    "        DJANGO_SECRET_KEY=\"-=(gyah-@e$-ymbz02mhwu6461zv&1&8uojya413ylk!#bwa-l\",\n",
    "        DJANGO_ALLOW_ASYNC_UNSAFE=\"True\"\n",
    "    )\n",
    "\n",
    "    django.setup()\n",
    "    os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"api.settings\")\n",
    "    from tables.models import Run, Instance, Detection, Product, Source\n",
    "    from tables.models import SourceDetection, Comment, Tag, TagDetection, TagSourceDetection\n",
    "    return\n",
    "\n",
    "def Aconn():\n",
    "    global Run, Instance, Detection, Product, Source\n",
    "    global SourceDetection, Comment, Tag, TagDetection, TagSourceDetection\n",
    "    os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"api.settings\")\n",
    "    os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "    import django\n",
    "    django.setup()\n",
    "    from tables.models import Run, Instance, Detection, Product, Source\n",
    "    from tables.models import SourceDetection, Comment, Tag, TagDetection, TagSourceDetection\n",
    "\n",
    "\n",
    "\n",
    "#import wallaby_data_access as wallaby\n",
    "#wallaby.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd058035-e24b-4c3d-8e4c-21696ca0e441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<QuerySet []>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do not include Wallaby Package, or uninstall package.\n",
    "Aconn()\n",
    "#import sys\n",
    "#for s in dir(settings):\n",
    "#    print(\"%s:%s:%s\",s, ':', getattr(settings, s))\n",
    "#print(sys.path)\n",
    "Tag.objects.all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d015d827-e6c4-469f-aaba-c2e3128313a5",
   "metadata": {},
   "source": [
    "## Retrieve Catalogue\n",
    "\n",
    "Once you are connected, you can then use the `wallaby.get_catalog()` function to retrieve the source catalogue as an Astropy table object. Catalogues are retrieved by tag, where tags define different collections of sources, e.g. all sources from a specific data release. The following tags are currently supported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "052c594e-51a0-4663-b04a-48f6d1b6cb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tags()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beaccff-41ea-44fc-8f73-4e2bcae6f958",
   "metadata": {},
   "source": [
    "As an example, let us retrieve all sources from phase 2 pilot observations released as part of the NGC 5044 DR1 release by supplying the `NGC 5044 DR1` tag to the `wallaby.get_catalog()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf00d112-1d0a-46a4-a9ba-e5118caa7747",
   "metadata": {},
   "outputs": [
    {
     "ename": "DoesNotExist",
     "evalue": "Tag matching query does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDoesNotExist\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_353/1606457873.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Retrieve catalogue as Astropy table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_catalog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NGC 5044 DR1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Sort table by flux (brightest first)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_353/1735852254.py\u001b[0m in \u001b[0;36mget_catalog\u001b[0;34m(tag)\u001b[0m\n\u001b[1;32m     97\u001b[0m         Source.objects.get(id=sd.source_id) for sd in [\n\u001b[1;32m     98\u001b[0m             \u001b[0mSourceDetection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtsd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_detection_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtsd\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mTagSourceDetection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         ]\n\u001b[1;32m    101\u001b[0m     ]\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/django/db/models/manager.py\u001b[0m in \u001b[0;36mmanager_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcreate_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mmanager_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_queryset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mmanager_method\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mmanager_method\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/django/db/models/query.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             raise self.model.DoesNotExist(\n\u001b[0m\u001b[1;32m    436\u001b[0m                 \u001b[0;34m\"%s matching query does not exist.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDoesNotExist\u001b[0m: Tag matching query does not exist."
     ]
    }
   ],
   "source": [
    "# Retrieve catalogue as Astropy table\n",
    "from astropy.table import Table\n",
    "table = get_catalog(\"NGC 5044 DR1\");\n",
    "\n",
    "# Sort table by flux (brightest first)\n",
    "table.sort(\"f_sum\", reverse=True)\n",
    "\n",
    "# Print table\n",
    "table.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60e54d6-86ab-45ff-9053-982de8348e51",
   "metadata": {},
   "source": [
    "The source catalogue returned by the function should have been printed above (if not, check for error messages) and is stored in the variable `table`. We can now use basic indexing to access different catalogue entries. For example, `table[\"f_sum\"]` will return the entire column of integrated flux measurements, and we can use `table[\"f_sum\"][0]` etc. to extract the individual fluxes for each source. Likewise, `table[0]` will extract the entire first row of the catalogue, i.e. a list of all parameters of the first source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6731150b-557f-431c-9010-047883e7876f",
   "metadata": {},
   "source": [
    "## Calculate Physical Parameters\n",
    "\n",
    "The next example demonstrates how to retrieve certain parameters from the catalogue and use basic arithmetic to convert some of the raw measurements made by SoFiA into physically meaningful parameters such as redshift or HI mass. These can be directly appended to the catalogue as additional columns using `table[\"parameter_name\"] = <expression>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9db3721a-c9bf-46ca-ab1b-51580b9aaa95",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_353/4146460926.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Calculate redshift\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"redshift\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_rest\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"freq\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Calculate luminosity distance in Mpc and HI mass in solar masses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'table' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.constants as const\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "\n",
    "# Set up cosmology\n",
    "f_rest = 1.42040575e+9;  # HI rest frequency in Hz\n",
    "cosmo = FlatLambdaCDM(H0=70, Om0=0.3, Tcmb0=2.725)\n",
    "\n",
    "# Calculate redshift\n",
    "table[\"redshift\"] = f_rest / table[\"freq\"] - 1.0\n",
    "\n",
    "# Calculate luminosity distance in Mpc and HI mass in solar masses\n",
    "table[\"dl\"] = cosmo.luminosity_distance(table[\"redshift\"]).value\n",
    "table[\"log_mhi\"] = np.log10(49.7 * table[\"dl\"] * table[\"dl\"] * table[\"f_sum\"])\n",
    "\n",
    "# Calculate source rest frame velocity width in km/s\n",
    "table[\"dv\"] = const.c * (1.0 + table[\"redshift\"]) * table[\"w20\"] / f_rest / 1000.0\n",
    "\n",
    "# Show our new parameters\n",
    "table[\"name\", \"id\", \"redshift\", \"dl\", \"log_mhi\", \"dv\"].pprint(max_width=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae12e45-cd45-463d-8877-3a75ee266e65",
   "metadata": {},
   "source": [
    "## Create a Plot\n",
    "\n",
    "Once we’ve done our analysis, we can the create plots of any of the parameters in our table. In this example, let us plot the logarithmic HI mass against redshift and additionally colour the data points by source rest frame velocity width. If desired, the resulting plot can be exported as a PDF file and then downloaded to your local computer, e.g. to use in a presentation or publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d937607a-4062-4ef7-a1b7-a98ec076c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "\n",
    "plt.scatter(table[\"redshift\"], table[\"log_mhi\"], s=16, c=table[\"dv\"], cmap=\"jet\")\n",
    "plt.xlabel(r\"$z$\")\n",
    "plt.ylabel(r\"$\\log_{10}(M_{\\rm HI} / M_{\\odot})$\")\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(r\"$\\Delta v \\; (\\mathrm{km \\, s}^{-1})$\")\n",
    "plt.xlim(0.0, 0.1)\n",
    "plt.ylim(7.0, 11.0)\n",
    "plt.grid(True)\n",
    "\n",
    "# Uncomment the following line to make a PDF copy in the notebook folder for download\n",
    "#plt.savefig(\"my_plot.pdf\", format=\"pdf\", bbox_inches=\"tight\", pad_inches=0.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477fc82d-2ba8-41ad-b599-ab68b521b330",
   "metadata": {},
   "source": [
    "## Filtering the catalogue\n",
    "\n",
    "Once we have the catalogue loaded into an Astropy table object, we can easily make selections to suit our scientific needs. The following examples illustrate how the catalogue can be filtered by certain criteria such as parameter ranges or the presence of comments and tags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81466586-c37b-4844-8726-8d9c32665103",
   "metadata": {},
   "source": [
    "**Example 1: Filter sources by parameter range**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981ee7fe-acdc-426c-ae6c-374969834765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all sources within a certain RA and Dec range\n",
    "\n",
    "mask = (table[\"ra\"] > 202.0) & (table[\"ra\"] < 203.0) & (table[\"dec\"] > -22.5) & (table[\"dec\"] < -21.5)\n",
    "table[mask].pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1982d3b-b509-4530-91da-d30850405222",
   "metadata": {},
   "source": [
    "**Example 2: Filter sources tagged as components of a galaxy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f1c530-c085-4b0e-b577-257b5b6449c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all sources that have the \"Component\" tag set\n",
    "\n",
    "mask = [\"Component\" in tags for tags in table[\"tags\"]]\n",
    "table[mask][\"name\", \"id\", \"tags\"].pprint_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81492acc-95b5-4692-b9ff-eac2077b69ab",
   "metadata": {},
   "source": [
    "**Example 3: Filter sources that have comments attached**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beabaa0d-7274-4da6-937e-bcef08cbb27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all sources with at least one comment\n",
    "\n",
    "mask = [len(comments) > 0 for comments in table[\"comments\"]]\n",
    "table[mask][\"name\", \"id\", \"comments\"].pprint_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7a3ccf-972d-4686-ac38-c97af2a62846",
   "metadata": {},
   "source": [
    "## Create overview plot for a specific source\n",
    "\n",
    "It is also possible to display an overview plot of a specific source (as identified by its catalogue ID) by calling the `wallaby.overview_plot()` function. That function will display four panels showing the moment 0 and 1 maps, a DSS image with HI contours and the integrated spectrum of the source. **Note that it may take up to half a minute before the plot is displayed, as Astropy must download the DSS image from Skyview first.** If the Skyview download fails, which happens occasionally, just try again a few hours later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17565218-bbc9-43e9-a562-2503db4bd116",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt = wallaby.overview_plot(id=4713)\n",
    "\n",
    "# Uncomment the following line to make a PDF copy in the notebook folder for download\n",
    "#plt.savefig(\"my_plot.pdf\", format=\"pdf\", bbox_inches=\"tight\", pad_inches=0.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c590227e-e2fa-4ed7-8cbd-05423a23b118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
